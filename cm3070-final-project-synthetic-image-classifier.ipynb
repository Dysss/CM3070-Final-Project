{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Installation and importing of relevant packages"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install numpy\n","# !pip install pandas\n","# !pip install tensorflow\n","# !pip install scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Import relevant libraries\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","import skimage as skimg\n","import matplotlib.pyplot as plt\n","from scipy.signal import convolve2d\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Setup file paths"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Show file directory structure\n","# print(os.listdir('/kaggle/input/cifake-real-and-ai-generated-synthetic-images'))\n","\n","# Setup file directories\n","fake_test_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE/'\n","real_test_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL/'\n","fake_train_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE/'\n","real_train_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL/'\n","\n","fake_test_files = os.listdir(fake_test_dir)\n","real_test_files = os.listdir(real_test_dir)\n","fake_train_files = os.listdir(fake_train_dir)\n","real_train_files = os.listdir(real_train_dir)"]},{"cell_type":"markdown","metadata":{},"source":["# Basic data pre-processing"]},{"cell_type":"markdown","metadata":{},"source":["## Construct training data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Construct real training set\n","real_train_paths = []\n","\n","for filename in real_train_files:\n","    real_train_paths.append(real_train_dir + filename)          # Append full path of each file to real_train_paths\n","\n","real_train_paths = pd.DataFrame(real_train_paths)               # Construct dataframe using real_train_paths\n","real_train_paths.columns = ['path']                             # Label column 'path'\n","real_train_paths['label'] = 0                                   # Add column 'label' with value = 0\n","\n","print(f\"Length of real_train_paths: {len(real_train_paths)}\")\n","\n","# Construct fake training set\n","fake_train_paths = []\n","\n","for filename in fake_train_files:\n","    fake_train_paths.append(fake_train_dir + filename)          # Append full path of each file to fake_train_paths\n","\n","fake_train_paths = pd.DataFrame(fake_train_paths)               # Construct dataframe using real_train_paths\n","fake_train_paths.columns = ['path']                             # Label column 'path'\n","fake_train_paths['label'] = 1                                   # Add column 'label' with value = 1\n","\n","print(f\"Length of fake_train_paths: {len(fake_train_paths)}\")\n","\n","# Combine both sets for general training set\n","train_set = pd.concat((real_train_paths, fake_train_paths), axis=0)\n","print(f\"train_set shape: {train_set.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Shuffle rows\n","train_set = train_set.sample(frac=1).reset_index(drop=True)\n","\n","train_set.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Split into training and validation sets\n","train_set, val_set = np.split(train_set, [int(0.8*len(train_set))])\n","\n","print(train_set.head())\n","print(val_set.head())"]},{"cell_type":"markdown","metadata":{},"source":["## Extract pixel data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Extract training image data\n","train_set_data = []\n","\n","for image in train_set['path']:\n","    image_data = skimg.io.imread(image)             # Extract image data\n","    train_set_data.append(image_data)               # Append to list for construction of numpy array later on\n","\n","image_array = np.array(train_set_data)              # Construct numpy array using the list\n","X_train = image_array/255                           # Normalize values to [0, 1]\n","print(X_train.shape)                                # Check that we have the right shape\n","\n","# Extract training image labels\n","y_train = train_set['label']\n","y_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Extract validation image data\n","val_set_data = []\n","\n","for image in val_set['path']:\n","    image_data = skimg.io.imread(image)             # Extract image data\n","    val_set_data.append(image_data)                 # Append to list for construction of numpy array later on\n","\n","image_array = np.array(val_set_data)                # Construct numpy array using the list\n","X_val = image_array/255                             # Normalize values to [0, 1]\n","print(X_val.shape)                                         # Check that we have the right shape\n","\n","# Extract training image labels\n","y_val = val_set['label']\n","y_val.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Construct testing data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Construct real testing set\n","real_test_paths = []\n","\n","for filename in real_test_files:\n","    real_test_paths.append(real_test_dir + filename)            # Append full path of each file to real_test_paths\n","\n","real_test_paths = pd.DataFrame(real_test_paths)                 # Construct dataframe using real_test_paths\n","real_test_paths.columns = ['path']                              # Label column 'path'\n","real_test_paths['label'] = 0                                    # Add column 'label' with value = 0\n","\n","print(f\"Length of real_test_paths: {len(real_test_paths)}\")\n","\n","# Construct fake testing set\n","fake_test_paths = []\n","\n","for filename in fake_test_files:\n","    fake_test_paths.append(fake_test_dir + filename)            # Append full path of each file to fake_test_paths\n","\n","fake_test_paths = pd.DataFrame(fake_test_paths)                 # Construct dataframe using real_test_paths\n","fake_test_paths.columns = ['path']                              # Label column 'path'\n","fake_test_paths['label'] = 1                                    # Add column 'label' with value = 1\n","\n","print(f\"Length of fake_test_paths: {len(fake_test_paths)}\")\n","\n","# Combine both sets for general training set\n","test_set = pd.concat((real_test_paths, fake_test_paths), axis=0)\n","\n","print(f\"test_set shape: {test_set.shape}\")\n","test_set.sample(5)"]},{"cell_type":"markdown","metadata":{},"source":["## Extract pixel data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Extract testing image data\n","test_set_data = []\n","\n","for image in test_set['path']:\n","    image_data = skimg.io.imread(image)         # Extract image data\n","    test_set_data.append(image_data)            # Append to list for construction of numpy array later on\n","\n","image_array = np.array(test_set_data)           # Construct numpy array using the list\n","X_test = image_array/255                        # Normalize values to [0, 1]\n","print(X_test.shape)                             # Check that we have the right shape\n","\n","# Extract training image labels\n","y_test = test_set['label']\n","y_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Build baseline model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Model architecture\n","base_model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(10, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","base_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train model\n","history = base_model.fit(\n","    X_train,\n","    y_train,\n","    epochs=5,\n","    validation_data=(X_val, y_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Evaluate model\n","base_model.evaluate(X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Grayscale testing"]},{"cell_type":"markdown","metadata":{},"source":["## Convert image data to grayscale"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Grayscale conversion function\n","def toGrayscale(imgArr):\n","    ratio = [0.299, 0.587, 0.114]                            # NTSC Formula\n","    \n","    grayImgArr = []\n","    \n","    for img in imgArr:\n","        grayImg = []\n","        \n","        for y_ind in img:\n","            grayRow = []\n","            \n","            for x_ind in y_ind:\n","                grayVal = np.dot(x_ind, ratio)               # Use numpy dot to apply ratio/formula\n","                grayPix = grayVal\n","                grayRow.append(grayPix)\n","                \n","            grayImg.append(grayRow)\n","            \n","        grayImgArr.append(grayImg)\n","        \n","    return np.array(grayImgArr)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert data to grayscale\n","X_gs_train = toGrayscale(X_train)\n","y_gs_train = y_train\n","X_gs_val = toGrayscale(X_val)\n","y_gs_val = y_val\n","X_gs_test = toGrayscale(X_test)\n","y_gs_test = y_test"]},{"cell_type":"markdown","metadata":{},"source":["## Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Model architecture\n","gs_model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(10, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","gs_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gs_history = gs_model.fit(\n","    X_gs_train,\n","    y_gs_train,\n","    epochs=5,    # 50 for real training\n","    validation_data=(X_gs_val, y_gs_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gs_model.evaluate(X_gs_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Frequency Domain extraction testing"]},{"cell_type":"markdown","metadata":{},"source":["## Convert image to frequency domain"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def toFreqDomain(imgArr):\n","    gsArr = toGrayscale(imgArr)\n","    freqDomArr = []\n","    \n","    for img in gsArr:\n","        fftImg = np.fft.fft2(img)\n","        fftImgShift = np.fft.fftshift(fftImg)\n","        imgMagnitude = 20 * np.log(np.abs(fftImgShift))\n","        \n","        minMag = np.min(imgMagnitude)\n","        maxMag = np.max(imgMagnitude)\n","        normalized = (imgMagnitude - minMag) / (maxMag - minMag)\n","        \n","        freqDomArr.append(normalized)\n","    \n","    return np.array(freqDomArr)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_fft_train = toFreqDomain(X_train)\n","y_fft_train = y_train\n","X_fft_val = toFreqDomain(X_val)\n","y_fft_val = y_val\n","X_fft_test = toFreqDomain(X_test)\n","y_fft_test = y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_fft_train[0]"]},{"cell_type":"markdown","metadata":{},"source":["## Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Model architecture\n","fft_model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(10, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","fft_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fft_history = fft_model.fit(\n","    X_fft_train,\n","    y_fft_train,\n","    epochs=5,    # 50 for real training\n","    validation_data=(X_fft_val, y_fft_val)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Edge detection testing"]},{"cell_type":"markdown","metadata":{},"source":["## Perform edge detection on image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def edgeDetect(imgArr):\n","    edgeArr = []\n","    gsImgArr = toGrayscale(imgArr)\n","    \n","    xKernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n","    yKernel = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n","    \n","    for img in gsImgArr:\n","        xGrad = convolve2d(img, xKernel, mode='same', boundary='symm')\n","        yGrad = convolve2d(img, yKernel, mode='same', boundary='symm')\n","        \n","        edgeMagnitude = np.sqrt(xGrad**2 + yGrad**2)\n","        \n","        edgeArr.append(edgeMagnitude)\n","        \n","    return np.array(edgeArr)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert data to grayscale\n","X_edge_train = edgeDetect(X_train)\n","y_edge_train = y_train\n","X_edge_val = edgeDetect(X_val)\n","y_edge_val = y_val\n","X_edge_test = edgeDetect(X_test)\n","y_edge_test = y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Model architecture\n","edge_model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(10, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","edge_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_edge_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["edge_history = edge_model.fit(\n","    X_edge_train,\n","    y_edge_train,\n","    epochs=5,    # 50 for real training\n","    validation_data=(X_edge_val, y_edge_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["edge_model.evaluate(X_edge_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter testing"]},{"cell_type":"markdown","metadata":{},"source":["## Model A"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model architecture\n","model_a = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(32,32,3)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","model_a.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train model\n","history_a = model_a.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,    # 50 for real training\n","    validation_data=(X_val, y_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_a.evaluate(X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["## Model B"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model architecture\n","model_b = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","model_b.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train model\n","history_b = model_b.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,    # 50 for real training\n","    validation_data=(X_val, y_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Evaluate model\n","model_b.evaluate(X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Final model build"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Model architecture\n","final_model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3)),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","final_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train model\n","final_history = final_model.fit(\n","    X_train,\n","    y_train,\n","    epochs=50,    # 50 for real training\n","    validation_data=(X_val, y_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_model.evaluate(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_model.save(\"ai_image_prediction_model.keras\")"]},{"cell_type":"markdown","metadata":{},"source":["# DUMMY TESTING"]},{"cell_type":"markdown","metadata":{},"source":["# Building a model that handles multiple inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Base layers\n","baseInput = keras.Input(shape=(32,32,3))\n","baseLayers = keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3))(baseInput)\n","baseLayers = keras.layers.MaxPooling2D(pool_size=(2, 2))(baseLayers)\n","baseLayers = keras.layers.Flatten()(baseLayers)\n","# baseLayers = keras.layers.Dense(10, activation='relu')(baseLayers)\n","# baseLayers = keras.layers.Dense(1, activation='sigmoid')(baseLayers)\n","\n","baseModel = keras.Model(inputs=baseInput, outputs=baseLayers, name=\"Base_model\")\n","\n","# Grayscale layers\n","gsInput = keras.Input(shape=(32,32,1))\n","gsLayers = keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3))(gsInput)\n","gsLayers = keras.layers.MaxPooling2D(pool_size=(2, 2))(gsLayers)\n","gsLayers = keras.layers.Flatten()(gsLayers)\n","# gsLayers = keras.layers.Dense(10, activation='relu')(gsLayers)\n","# gsLayers = keras.layers.Dense(1, activation='sigmoid')(gsLayers)\n","\n","gsModel = keras.Model(inputs=gsInput, outputs=gsLayers, name=\"Grayscale_model\")\n","\n","# # FFT layers\n","# fftInput = keras.Input(32,32,1)\n","\n","# # Edge detection layers\n","# edgeInput = keras.Input(32,32,1)\n","\n","combinedOutput = keras.layers.concatenate([baseModel.output, gsModel.output])\n","denseLayers = keras.layers.Dense(64)(combinedOutput)\n","denseLayers = keras.layers.Dense(1)(denseLayers)\n","\n","combinedModel = keras.Model(inputs=[baseModel.input, gsModel.input], outputs=denseLayers, name=\"Combined_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["keras.utils.plot_model(combinedModel, \"combinedModel.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["combinedModel.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss=\"binary_crossentropy\",\n","    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["combinedHistory = combinedModel.fit(\n","    x=[X_train, X_gs_train],\n","    y=y_train,\n","    epochs=5,\n","    validation_data=([X_val, X_gs_val], y_val)\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
