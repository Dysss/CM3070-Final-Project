{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation and importing of relevant packages","metadata":{}},{"cell_type":"code","source":"# !pip install numpy\n# !pip install pandas\n# !pip install tensorflow\n# !pip install scikit-image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import relevant libraries\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nimport skimage as skimg\nimport matplotlib.pyplot as plt\nfrom scipy.signal import convolve2d\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup file paths","metadata":{}},{"cell_type":"code","source":"# Show file directory structure\n# print(os.listdir('/kaggle/input/cifake-real-and-ai-generated-synthetic-images'))\n\n# Setup file directories\nfake_test_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE/'\nreal_test_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL/'\nfake_train_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE/'\nreal_train_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/REAL/'\n\nfake_test_files = os.listdir(fake_test_dir)\nreal_test_files = os.listdir(real_test_dir)\nfake_train_files = os.listdir(fake_train_dir)\nreal_train_files = os.listdir(real_train_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic data pre-processing","metadata":{}},{"cell_type":"markdown","source":"## Construct training data","metadata":{}},{"cell_type":"code","source":"# Construct real training set\nreal_train_paths = []\n\nfor filename in real_train_files:\n    real_train_paths.append(real_train_dir + filename)          # Append full path of each file to real_train_paths\n\nreal_train_paths = pd.DataFrame(real_train_paths)               # Construct dataframe using real_train_paths\nreal_train_paths.columns = ['path']                             # Label column 'path'\nreal_train_paths['label'] = 0                                   # Add column 'label' with value = 0\n\nprint(f\"Length of real_train_paths: {len(real_train_paths)}\")\n\n# Construct fake training set\nfake_train_paths = []\n\nfor filename in fake_train_files:\n    fake_train_paths.append(fake_train_dir + filename)          # Append full path of each file to fake_train_paths\n\nfake_train_paths = pd.DataFrame(fake_train_paths)               # Construct dataframe using real_train_paths\nfake_train_paths.columns = ['path']                             # Label column 'path'\nfake_train_paths['label'] = 1                                   # Add column 'label' with value = 1\n\nprint(f\"Length of fake_train_paths: {len(fake_train_paths)}\")\n\n# Combine both sets for general training set\ntrain_set = pd.concat((real_train_paths, fake_train_paths), axis=0)\nprint(f\"train_set shape: {train_set.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle rows\ntrain_set = train_set.sample(frac=1).reset_index(drop=True)\n\ntrain_set.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and validation sets\ntrain_set, val_set = np.split(train_set, [int(0.8*len(train_set))])\n\nprint(train_set.head())\nprint(val_set.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract pixel data","metadata":{}},{"cell_type":"code","source":"# Extract training image data\ntrain_set_data = []\n\nfor image in train_set['path']:\n    image_data = skimg.io.imread(image)             # Extract image data\n    train_set_data.append(image_data)               # Append to list for construction of numpy array later on\n\nimage_array = np.array(train_set_data)              # Construct numpy array using the list\nX_train = image_array/255                           # Normalize values to [0, 1]\nprint(X_train.shape)                                # Check that we have the right shape\n\n# Extract training image labels\ny_train = train_set['label']\ny_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract validation image data\nval_set_data = []\n\nfor image in val_set['path']:\n    image_data = skimg.io.imread(image)             # Extract image data\n    val_set_data.append(image_data)                 # Append to list for construction of numpy array later on\n\nimage_array = np.array(val_set_data)                # Construct numpy array using the list\nX_val = image_array/255                             # Normalize values to [0, 1]\nprint(X_val.shape)                                         # Check that we have the right shape\n\n# Extract training image labels\ny_val = val_set['label']\ny_val.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Construct testing data","metadata":{}},{"cell_type":"code","source":"# Construct real testing set\nreal_test_paths = []\n\nfor filename in real_test_files:\n    real_test_paths.append(real_test_dir + filename)            # Append full path of each file to real_test_paths\n\nreal_test_paths = pd.DataFrame(real_test_paths)                 # Construct dataframe using real_test_paths\nreal_test_paths.columns = ['path']                              # Label column 'path'\nreal_test_paths['label'] = 0                                    # Add column 'label' with value = 0\n\nprint(f\"Length of real_test_paths: {len(real_test_paths)}\")\n\n# Construct fake testing set\nfake_test_paths = []\n\nfor filename in fake_test_files:\n    fake_test_paths.append(fake_test_dir + filename)            # Append full path of each file to fake_test_paths\n\nfake_test_paths = pd.DataFrame(fake_test_paths)                 # Construct dataframe using real_test_paths\nfake_test_paths.columns = ['path']                              # Label column 'path'\nfake_test_paths['label'] = 1                                    # Add column 'label' with value = 1\n\nprint(f\"Length of fake_test_paths: {len(fake_test_paths)}\")\n\n# Combine both sets for general training set\ntest_set = pd.concat((real_test_paths, fake_test_paths), axis=0)\n\nprint(f\"test_set shape: {test_set.shape}\")\ntest_set.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract pixel data","metadata":{}},{"cell_type":"code","source":"# Extract testing image data\ntest_set_data = []\n\nfor image in test_set['path']:\n    image_data = skimg.io.imread(image)         # Extract image data\n    test_set_data.append(image_data)            # Append to list for construction of numpy array later on\n\nimage_array = np.array(test_set_data)           # Construct numpy array using the list\nX_test = image_array/255                        # Normalize values to [0, 1]\nprint(X_test.shape)                             # Check that we have the right shape\n\n# Extract training image labels\ny_test = test_set['label']\ny_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build baseline model","metadata":{}},{"cell_type":"code","source":"# Model architecture\nbase_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nbase_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"# Train model\nhistory = base_model.fit(\n    X_train,\n    y_train,\n    epochs=5,\n    validation_data=(X_val, y_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model\nbase_model.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grayscale testing","metadata":{}},{"cell_type":"markdown","source":"## Convert image data to grayscale","metadata":{}},{"cell_type":"code","source":"# Grayscale conversion function\ndef toGrayscale(imgArr):\n    ratio = [0.299, 0.587, 0.114]                            # NTSC Formula\n    \n    grayImgArr = []\n    \n    for img in imgArr:\n        grayImg = []\n        \n        for y_ind in img:\n            grayRow = []\n            \n            for x_ind in y_ind:\n                grayVal = np.dot(x_ind, ratio)               # Use numpy dot to apply ratio/formula\n                grayPix = grayVal\n                grayRow.append(grayPix)\n                \n            grayImg.append(grayRow)\n            \n        grayImgArr.append(grayImg)\n        \n    return np.array(grayImgArr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert data to grayscale\nX_gs_train = toGrayscale(X_train)\ny_gs_train = y_train\nX_gs_val = toGrayscale(X_val)\ny_gs_val = y_val\nX_gs_test = toGrayscale(X_test)\ny_gs_test = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build model","metadata":{}},{"cell_type":"code","source":"# Model architecture\ngs_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\ngs_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_history = gs_model.fit(\n    X_gs_train,\n    y_gs_train,\n    epochs=5,    # 50 for real training\n    validation_data=(X_gs_val, y_gs_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_model.evaluate(X_gs_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Frequency Domain extraction testing","metadata":{}},{"cell_type":"markdown","source":"## Convert image to frequency domain","metadata":{}},{"cell_type":"code","source":"def toFreqDomain(imgArr):\n    gsArr = toGrayscale(imgArr)\n    freqDomArr = []\n    \n    for img in gsArr:\n        fftImg = np.fft.fft2(img)\n        fftImgShift = np.fft.fftshift(fftImg)\n        imgMagnitude = 20 * np.log(np.abs(fftImgShift))\n        \n        minMag = np.min(imgMagnitude)\n        maxMag = np.max(imgMagnitude)\n        normalized = (imgMagnitude - minMag) / (maxMag - minMag)\n        \n        freqDomArr.append(normalized)\n    \n    return np.array(freqDomArr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_fft_train = toFreqDomain(X_train)\ny_fft_train = y_train\nX_fft_val = toFreqDomain(X_val)\ny_fft_val = y_val\nX_fft_test = toFreqDomain(X_test)\ny_fft_test = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_fft_train[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build model","metadata":{}},{"cell_type":"code","source":"# Model architecture\nfft_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nfft_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fft_history = fft_model.fit(\n    X_fft_train,\n    y_fft_train,\n    epochs=5,    # 50 for real training\n    validation_data=(X_fft_val, y_fft_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Edge detection testing","metadata":{}},{"cell_type":"markdown","source":"## Perform edge detection on image","metadata":{}},{"cell_type":"code","source":"def edgeDetect(imgArr):\n    edgeArr = []\n    gsImgArr = toGrayscale(imgArr)\n    \n    xKernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n    yKernel = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n    \n    for img in gsImgArr:\n        xGrad = convolve2d(img, xKernel, mode='same', boundary='symm')\n        yGrad = convolve2d(img, yKernel, mode='same', boundary='symm')\n        \n        edgeMagnitude = np.sqrt(xGrad**2 + yGrad**2)\n        \n        edgeArr.append(edgeMagnitude)\n        \n    return np.array(edgeArr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert data to grayscale\nX_edge_train = edgeDetect(X_train)\ny_edge_train = y_train\nX_edge_val = edgeDetect(X_val)\ny_edge_val = y_val\nX_edge_test = edgeDetect(X_test)\ny_edge_test = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model architecture\nedge_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nedge_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_edge_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edge_history = edge_model.fit(\n    X_edge_train,\n    y_edge_train,\n    epochs=5,    # 50 for real training\n    validation_data=(X_edge_val, y_edge_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edge_model.evaluate(X_edge_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter testing","metadata":{}},{"cell_type":"markdown","source":"## Model A","metadata":{}},{"cell_type":"code","source":"# Model architecture\nmodel_a = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(32,32,3)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nmodel_a.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory_a = model_a.fit(\n    X_train,\n    y_train,\n    epochs=50,    # 50 for real training\n    validation_data=(X_val, y_val)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_a.evaluate(X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model B","metadata":{}},{"cell_type":"code","source":"# Model architecture\nmodel_b = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nmodel_b.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory_b = model_b.fit(\n    X_train,\n    y_train,\n    epochs=50,    # 50 for real training\n    validation_data=(X_val, y_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model\nmodel_b.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final model build","metadata":{}},{"cell_type":"code","source":"# Model architecture\nfinal_model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,3)),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nfinal_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nfinal_history = final_model.fit(\n    X_train,\n    y_train,\n    epochs=50,    # 50 for real training\n    validation_data=(X_val, y_val)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model.save(\"ai_image_prediction_model.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DUMMY TESTING","metadata":{}},{"cell_type":"markdown","source":"# Building a model that handles multiple inputs","metadata":{}},{"cell_type":"code","source":"# Base layers\nbaseInput = keras.Input(shape=(32,32,3))\nbaseLayers = keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3))(baseInput)\nbaseLayers = keras.layers.MaxPooling2D(pool_size=(2, 2))(baseLayers)\nbaseLayers = keras.layers.Flatten()(baseLayers)\n# baseLayers = keras.layers.Dense(10, activation='relu')(baseLayers)\n# baseLayers = keras.layers.Dense(1, activation='sigmoid')(baseLayers)\n\nbaseModel = keras.Model(inputs=baseInput, outputs=baseLayers, name=\"Base_model\")\n\n# Grayscale layers\ngsInput = keras.Input(shape=(32,32,1))\ngsLayers = keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3))(gsInput)\ngsLayers = keras.layers.MaxPooling2D(pool_size=(2, 2))(gsLayers)\ngsLayers = keras.layers.Flatten()(gsLayers)\n# gsLayers = keras.layers.Dense(10, activation='relu')(gsLayers)\n# gsLayers = keras.layers.Dense(1, activation='sigmoid')(gsLayers)\n\ngsModel = keras.Model(inputs=gsInput, outputs=gsLayers, name=\"Grayscale_model\")\n\n# # FFT layers\n# fftInput = keras.Input(32,32,1)\n\n# # Edge detection layers\n# edgeInput = keras.Input(32,32,1)\n\ncombinedOutput = keras.layers.concatenate([baseModel.output, gsModel.output])\ndenseLayers = keras.layers.Dense(64)(combinedOutput)\ndenseLayers = keras.layers.Dense(1)(denseLayers)\n\ncombinedModel = keras.Model(inputs=[baseModel.input, gsModel.input], outputs=denseLayers, name=\"Combined_model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(combinedModel, \"combinedModel.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combinedModel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[tf.keras.metrics.AUC(curve='ROC'), 'acc'],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combinedHistory = combinedModel.fit(\n    x=[X_train, X_gs_train],\n    y=y_train,\n    epochs=5,\n    validation_data=([X_val, X_gs_val], y_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testImg = skimg.io.imread('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/REAL/0823 (10).jpg')\ntestImg = skimg.io.imread('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test/FAKE/912 (10).jpg')\ntestImgGS = toGrayscale([testImg])[0]\n\nxKernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\nyKernel = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n\nxGrad = convolve2d(testImgGS, xKernel, mode='same', boundary='symm')\nyGrad = convolve2d(testImgGS, yKernel, mode='same', boundary='symm')\n\nedgeMagnitude = np.sqrt(xGrad**2 + yGrad**2)\n\nprint(testImgGS.shape)\n\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(testImg)\nplt.title(\"Original Image\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(edgeMagnitude, cmap='gray')\nplt.title(\"Sobel Edge Magnitude\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}